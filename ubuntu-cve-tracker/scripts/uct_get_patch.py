#!/usr/bin/env python3
"""
    Module to download patch files from UCT CVE entries
"""

from collections import defaultdict
from pathlib import Path
from typing import Tuple, Any
import re
import os
import logging
import argparse
import sys

import requests

from cve_lib import get_cve_list, load_cve

logging.basicConfig(level=logging.INFO)
log = logging.getLogger(__name__)
log.setLevel(logging.INFO)


def get_download_link(link: str) -> str:
    """
    Given patch link transforms it into a downloadable link

    Args:
        link: patch link to transform

    Returns:
        str: Downloadable patch link
    """

    # TODO: Needs significantly more cases to be handled
    #       and better heuristics

    # TODO: Figure out how we want to handle metadata
    if " " in link:
        link, metadata = link.split(" ")

    if "github" in link or "gitlab" in link:
        if not link.endswith(".patch"):
            return link + ".patch"
    if "a=commit;" in link:
        return link.replace("a=commit", "a=patch")

    if "a=commitdiff;" in link:
        return link.replace("a=commitdiff", "a=patch")

    if "gitweb" in link:
        return link.replace("commit", "patch")

    print("This link wasn't transformed!")
    print("Please implement in the get_download_link method")

    return link


def is_merge_commit(link: str, patch_file: str) -> bool:
    """
    Determines if a patch_file/link is/refers to a merge commit

    Args:
        link(str): Patch file link
        patch_file (str): Contents of the patch
    """
    # TODO: Improve heuristic to detect pull request links
    return ("pull" in link) or ("merge_requests" in link)


def split_merge_commit(merge_commit: str) -> list[str]:
    """
    Splits a merge commit into separate commits

    Args:
        merge_commit (str): merge commit to split

    Returns:
        list[str]: list of commits
    """
    commit_pattern = re.compile("^From [a-f0-9]{40} ")
    patch_num = len(re.findall(commit_pattern, merge_commit))

    if patch_num == 0:
        log.error("No commits detected in merge_commit")
        return [merge_commit]

    patches = []
    current_patch = ""

    for line in merge_commit.splitlines(True):
        if commit_pattern.match(line) and current_patch:
            patches.append(current_patch)
            current_patch = ""

        current_patch += line

    patches.append(current_patch)

    return patches


def check_rate_limit(patch_file: str) -> bool:
    """
    Checks if you have been rate limited depending on the contents received from your request

    Args:
        patch_file (str): content to parse for rate limit messages

    Returns:
        bool: Returns true if evidence of rate limiting is present otherwise false
    """

    # TODO: Improve heuristic for rate limit detection

    return r"<h1>Too many requests</h1>" in patch_file


def handle_auth_tokens() -> dict[str, str]:
    """
    Returns:
        dict[str, str]: Auth headers needed to prevent rate limiting
    """

    # Attempt to get GitHub auth token to prevent rate limiting
    github_token = os.getenv("GITHUB_TOKEN", None)

    headers = {}

    if github_token:
        log.debug("Set Authorization header to $GITHUB_TOKEN")
        headers["Authorization"] = f"token {github_token}"

    return headers


def get_uct_path(uct_path_str: str) -> Path | None:
    """
    Converts uct_path_str to a Path object and checks that the relevant dirs exist

    Args:
        uct_path_str (str): path to UCT repository

    Returns:
        (Path | None): Returns UCT path as Path object if it doesn't exist then None
    """
    if not uct_path_str:
        uct_path_str = os.getenv("UCT", "")

    if not uct_path_str:
        log.error("UCT path not specified and environment variable not set!")
        log.error("Cannot download patches until path or environment variable is set")
        return None

    uct_path = Path(uct_path_str)

    # Inform user if no embargoed dir found
    if not (uct_path / "embargoed").is_dir():
        log.info("No embargoed directory found in UCT")

    # Check UCT path and active CVE dirs exist
    if (not uct_path.is_dir()) or (not (uct_path / "active").is_dir()):
        log.error("%s or active dirs don't exist", str(uct_path))
        return None

    return uct_path


def get_cves(cve_ids: list[str], pkg: str, uct_path: Path) -> list[dict[str, Any]]:
    """
    Given list of cve_ids parses relevant UCT entries
    Args:
        cve_ids (list[str]): list of CVE ids, if list is empty search all cves matching package
        pkg (str): Used for filtering CVEs when all_cves is set
        uct_path (Path): Path to UCT repository

    Returns:
        list[dict[str, Any]]: List of UCT CVE files parsed as a dictionary
    """

    # If no cve_ids supplied search all CVEs
    all_cves = not cve_ids

    cves = []
    all_cve_ids, embargoed_cve_ids = get_cve_list()

    for cve_id in all_cve_ids if all_cves else cve_ids:
        cve_path = (
            uct_path
            / ("embargoed" if cve_id in embargoed_cve_ids else "active")
            / cve_id
        )

        try:
            cve = load_cve(str(cve_path.resolve()))
            # We need to filter by package if using all CVEs
            if all_cves:
                if pkg in cve["pkgs"].keys():
                    cves.append(cve)
            else:
                cves.append(cve)
        except ValueError:
            log.critical("Issue with %s", cve_id)
        except FileNotFoundError:
            log.info("Could not find %s (possibly embargoed)", cve_id)

    return cves


def get_uct_patch(
    cve_ids: list[str],
    pkg: str,
    dest: str = ".",
    uct_path_str: str = "",
    force: bool = False,
    silent: bool = False,
) -> list[Tuple[str, int]]:
    """
    Gets patch files from either the PATCH_DB or links present in
    the UCT entry if possible

    Args:
        cves (list[str]): list of CVES to search for patch files, if list is empty assume
                            we want all cves for the specified package
        pkg (str): limit patches to package (use when multiple packages for the same CVE)
        dest (str): file path to store found patch files (default: current path)
        uct_path_str (str): path to uct repository
        force (bool): Will download request contents even in case of rate limiting
        silent (bool): If set silences output

    Returns:
        list[Tuple[str, int]]: Returns list of how much many patches were downloaded for each CVE
                                as a tuple pair (cve, number_of_patches_downloaded)
    """
    if silent:
        # Disable all output
        log.setLevel(logging.CRITICAL + 1)

    uct_path = get_uct_path(uct_path_str)

    if uct_path is None:
        return []

    cves = get_cves(cve_ids, pkg, uct_path)

    if not cves:
        log.error("No CVEs found or supplied")
        return []

    # Stores number of patches downloaded for each CVE
    patch_stats: list[Tuple[str, int]] = []
    patch_files: dict[str, list[str]] = defaultdict(list[str])
    patch_dir = Path(dest)
    headers = handle_auth_tokens()

    if not patch_dir.is_dir():
        log.critical("Destination %s doesn't exist or isn't a directory", patch_dir.name)
        return []

    for cve in cves:
        cve_id = cve["Candidate"]
        if ("patches" in cve) and (pkg in cve["patches"]):
            for _, patch_link in cve["patches"][pkg]:
                download_link = get_download_link(patch_link)

                try:
                    patch_file = requests.get(
                        download_link, headers=headers, timeout=10
                    ).text

                    if check_rate_limit(patch_file):
                        log.error(
                            'You have been rate limited when trying to download "%s"',
                            download_link,
                        )
                        log.error("Skipping patch")
                        log.error(
                            "In the case of GitHub or GitLab patch links please"
                            "add env variables to reduce rate limits"
                        )

                        # TODO: Detect github/gitlab links and link to how to setup auth token
                        if not force:
                            continue

                    if is_merge_commit(download_link, patch_file):
                        start_len = len(patch_files[cve_id])
                        patch_files[cve_id].extend(split_merge_commit(patch_file))
                        log.info(
                            "Merge commit detected (Patches %s-%s)",
                            start_len,
                            len(patch_files[cve_id]),
                        )
                    else:
                        patch_files[cve_id].append(patch_file)
                except requests.exceptions.RequestException:
                    log.error(
                        "Failed to download %s patch from %s", cve_id, download_link
                    )

            num_patches = len(patch_files[cve_id])
            for index, patch in enumerate(patch_files[cve_id]):
                patch_path = patch_dir / (
                    (cve_id if num_patches == 1 else f"{cve_id}-{index + 1}") + ".patch"
                )
                with open(patch_path, "w", encoding="utf-8") as f:
                    f.write(patch)

                print(f"Downloaded Patch #{index + 1} for {cve_id}")

            patch_stats.append((cve_id, len(patch_files[cve_id])))
        else:
            print(f"No patch links found for {cve_id}")
            # If no patch links for pkg affected by CVE
            patch_stats.append((cve_id, 0))

    return patch_stats


def setup_parser():
    """
    Creates parser for arguments needed for get_uct_patch
    """
    argparser = argparse.ArgumentParser(
        description="Script for downloading CVE patches\n\nExample:\n\n\t./uct-get-patch --cves CVE-2025-1234 CVE-2024-2345 --pkg curl --dest /tmp --force",
        formatter_class=argparse.RawTextHelpFormatter,
    )
    argparser.add_argument(
        "--cves", type=str, nargs="*", help="CVEs to download patches for"
    )
    argparser.add_argument(
        "--dest", type=str, default=".", help="destination dir to download patches"
    )
    argparser.add_argument(
        "--pkg", type=str, required=True, help="filter patches by package"
    )
    argparser.add_argument("--uct-dir", type=str, help="UCT directory")
    argparser.add_argument(
        "--force",
        action="store_true",
        default=False,
        help="Save commit request when rate limited",
    )
    argparser.add_argument(
        "--silent", action="store_true", default=False, help="Silence output"
    )
    return argparser


if __name__ == "__main__":
    parser = setup_parser()
    (opt, args) = parser.parse_known_args()

    if opt.pkg is None:
        parser.print_help()
        sys.exit(1)

    valid_cves = []

    if opt.cves:
        for cve in opt.cves:
            if re.match(r"CVE-[0-9]{4}-[0-9]{4,7}", cve):
                valid_cves.append(cve)
                continue

            print(f"Ignoring {cve} as could not be recognized as a valid CVE ID")

    get_uct_patch(valid_cves, opt.pkg, opt.dest, opt.uct_dir, opt.force, opt.silent)

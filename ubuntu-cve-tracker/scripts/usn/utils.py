# -*- coding: utf-8 -*-
# Module containing helper functions for creating USNs
#
# Author: Nick Galanis <nick.galanis@canonical.com>
# Copyright (C) 2025 Canonical Ltd.
#
# This script is distributed under the terms and conditions of the GNU General
# Public License, "Version" 3 or later. See http://www.gnu.org/copyleft/gpl.html
# for details.
#

import gzip
import os
import re
import sys

import apt_pkg
import pgpy

import cve_lib
import lpl_common
from source_map import version_compare
from uct.config import read_uct_config

# List of currently supported Ubuntu releases
supported_releases = ['trusty', 'xenial', 'bionic', 'focal', 'jammy', 'noble', 'oracular', 'plucky']
# List of possible PPAs that a security update might land into
supported_ppas = ["archive", "esm-apps", "esm-infra", "esm-infra-legacy"]

UCT = os.environ.get("UCT", os.path.expandvars("$HOME/git-pulls/cve-tracker"))
USN_GH = os.environ.get("USN_GH", os.path.expandvars("$HOME/git-pulls/usn-repo"))

usn_number = os.environ.get("USN")
if usn_number is None:
    print("ERROR: Please specify a USN number with export USN=XXX-Y")
    exit(1)

env_packages = os.environ.get("SRCPKG")
if env_packages is None:
    print("ERROR: Please specify a source package for the USN")
    exit(1)

packages = env_packages.split()

# directory for the new USN files to be placed
new_usn_dir = os.path.join(USN_GH, f"new-usn-{usn_number}")

# Load the UCT configuration
config = read_uct_config()

# get access to the local mirrors
archive = config['packages_mirror']
cve_lib.check_mirror_timestamp(config, mirror='packages_mirror')
dists = '%s/dists' % (archive)

# re to filter debug binaries
filter_dbg = re.compile("-dbg(sym)?$")

# Initialize connection to launchpad
launchpad = lpl_common.connect()

class bcolors:
    OKGREEN = "\033[92m"
    WARNING = "\033[93m"
    FAIL = "\033[91m"
    ENDC = "\033[0m"

def print_error(text: str, end='\n') -> None:
    """Print error message"""
    print(bcolors.FAIL, '[X]', text.strip().replace('\n', '\n     ').ljust(80), bcolors.ENDC, end=end)

def print_success(text: str, end='\n') -> None:
    """Print success message"""
    print(bcolors.OKGREEN, '[O]', text.strip().replace('\n', '\n     ').ljust(80), bcolors.ENDC, end=end)

def print_info(text: str, end='\n') -> None:
    """Print info message"""
    print(bcolors.WARNING, '[.]', text.strip().replace('\n', '\n     ').ljust(80), bcolors.ENDC, end=end)

def remove_empty_fields(d):
    """
    Recursively remove empty dicts, lists, and None values from a USN.
    """
    if isinstance(d, dict):
        new_dict = {}
        for k, v in d.items():
            cleaned = remove_empty_fields(v)
            if cleaned not in ({}, [], None):
                new_dict[k] = cleaned
        return new_dict
    elif isinstance(d, list):
        return [remove_empty_fields(item) for item in d if remove_empty_fields(item) not in ({}, [], None)]
    else:
        return d

def clean_usn_description(full_usn_text):
    """
    Helper function to sanitize USN descriptions, for embeddings to be computed
    """
    #Split USN into paragraphs
    paragraphs = [p.strip() for p in re.split(r'\n\s*\n', full_usn_text) if p.strip()]
    
    cleaned_paragraphs = []
    for para in paragraphs:
        #Remove CVE info from the description
        cleaned = re.sub(r'\s*\(CVE-\d{4}-\d+(?:,\s*CVE-\d{4}-\d+)*\)\s*$', '', para)
        cleaned_paragraphs.append(cleaned.strip())

    return cleaned_paragraphs

def find_filename(release, arch, pkg_name):
    """
    Searches for a package in all possible components' `Packages.gz` files
    for a given release and architecture. Returns the path in which the package is published
    """
    components = ["main", "restricted", "universe", "multiverse"]
    dists_path = f"{dists}/{release}"
    for component in components:
        # try to find the packages.gz file
        if arch == "":
            pkg_file = f"{dists_path}/{component}/source/Sources.gz"
        # special case for "all" arch, which actually builds on amd64
        elif arch == "all":
            pkg_file = f"{dists_path}/{component}/binary-amd64/Packages.gz"
        else:
            pkg_file = f"{dists_path}/{component}/binary-{arch}/Packages.gz"
        if not os.path.exists(pkg_file):
            continue        
        # open each file and search for the binary package name
        with gzip.open(pkg_file, 'rt', encoding='utf-8') as f:
            in_package = False
            for line in f:
                # parse all the lines of the file until we find this package
                if line.startswith("Package:"):
                    dist_package_name = line.split(":", 1)[1].strip()
                    in_package = (pkg_name == dist_package_name)
                # if we find the filename element, we're processing a binary package
                elif in_package and line.startswith("Filename:"):
                    filename = line.split(":")[1]
                    # keep everything except the actual package name, which will be replaced by the new package because of the USN
                    link = filename.split("/")
                    final_link = "/".join(link[:-1])
                    return final_link.strip()
                # if we find a directory element, we're processing a source package
                elif in_package and line.startswith("Directory:"):
                    filename = line.split(":")[1]
                    # keep everything except the actual package name, which will be replaced by the new package because of the USN
                    link = filename.split("/")
                    final_link = "/".join(link)
                    return final_link.strip()
    # if we've reached this point, something has gone wrong with the link resolution
    # also take a look at the -security mirrors
    if "security" not in release:
        return find_filename(release + "-security", arch, pkg_name)
    print_error(f"Links not produced correctly for {release, arch, pkg_name}")
    return None

def translate_lp_link(link, release, is_source):
    """
    Translate a launchpad link to the link where the file lives in .ubuntu.comm
    """
    # the 2 possible destinations for a package
    published = 'http://security.ubuntu.com/ubuntu'
    ports     = 'http://ports.ubuntu.com'

    arch = ""
    # find the architecture if we're processing a binary file
    if not is_source:
        arch_match =re.search(r'([^_/]+)\.deb$', link)
        if arch_match:
            arch = arch_match.group(1)
        else:
            arch_match = re.search(r'_(.*?)\.ddeb', link)
            if arch_match:
                arch = arch_match.group(1)
            else:
                print(f"ERROR: Wrong architecture in binary file {link} in the USN")
                exit(1)
    # find the actual package name
    pkg = link.rsplit("/", 1)[-1]
    binary_name = pkg.split('_', 1)[0]
    # consult cve lib to see which archs land in ports.ubuntu.com
    if (not is_source) and (arch in cve_lib.ports_architectures):
        base = ports
    else:
        base = published

    # construct and return the final link
    path = find_filename(release, arch, binary_name)
    return f"{base}/{path}/{pkg}"

def is_pgp_signed(file_obj):
    """
    Check if the given file object contains a PGP signature.
    """
    # Ensure we're at the beginning of the file
    file_obj.seek(0)
    content = file_obj.read()
    file_obj.seek(0)
    
    return "-----BEGIN PGP SIGNED MESSAGE-----" in content

def extract_pgp_signed_content(file_obj, url):
    """
    Extract and return the signed content from a PGP-signed file object.
    """
    # Ensure we're at the beginning of the file
    file_obj.seek(0)
    signed_message = file_obj.read()
    file_obj.seek(0)

    try:
        msg = pgpy.PGPMessage.from_blob(signed_message)
        message = msg.message
        if isinstance(message, bytearray):
            print_info(f"WARNING: Possibly bad signature in file retrieved from {url}")
            message = message.decode('utf-8', errors='replace')
        return message
    except Exception as e:
        print_error(f"Error while extracting PGP signed file content: {e}")
        return signed_message

def parse_CVEs(text):
    """
    Return a set of all CVEs mentioned in the given text.
    Vendored from sis-generate-usn
    """
    # Looks for all CVE/CAN mentions
    result = set([])
    # Removing lines from debian/patches, so avoiding two checks for
    # CVE number and bugs.
    text = ' '.join(text.split('/CVE'))
    cvere = re.compile(r"((?:CVE|cve)-\d\d\d\d-\d{4,7})")
    for cve in cvere.finditer(text):
        cve_number = cve.group().upper()
        result.add(cve_number)

    return result

apt_pkg.init()

def download_and_parse_changes_file(url, release, binaries_dict, cves, is_source, is_esm):
    """
    Parses a launchpad url to a .changes file and return a dict 
    with the needed links to appear in the USN, along with their metadata (name, md5, size)
    """
    # Download the .changes file to a temporary file
    temp_filename = lpl_common.download(launchpad, url, rewrite_uri=True)

    try:
        # Check for PGP signature and extract content if signed
        with open(temp_filename, 'r+') as temp_file:
            if is_pgp_signed(temp_file):
                cleaned_content = extract_pgp_signed_content(temp_file, url)
                temp_file.seek(0)
                temp_file.truncate()
                temp_file.write(cleaned_content)

        with open(temp_filename, 'rb') as f:
            tagfile = apt_pkg.TagFile(f)
            # Get first (and only) section
            section = next(iter(tagfile), None)

            archs = {}
            if section:
                # Extract metadata
                files = section['Files'].strip()
                # Parse the Files section
                archs = get_changes_info(files, release, binaries_dict, is_source)
                if "_source.changes" in url:
                    cves.update(parse_CVEs(section['Changes']))
                return archs
    finally:
        os.unlink(temp_filename)

    return {}

def get_changes_info(files_field, release, binaries_dict, is_source):
    """
    Helper to extract the files metadata from the changes file
    """
    files_dict = {}
    for line in files_field.split("\n"):
        parts = line.split()
        # parsing a changes file
        if len(parts) >= 5:
            md5 = parts[0]
            size = int(parts[1])
            filename = parts[4]
        # parsing a dsc file
        elif len(parts) == 3:
            md5 = parts[0]
            size = int(parts[1])
            filename = parts[2]
        # wrong file format given
        else:
            print("ERROR: Changes file provided not in the correct format.")
            return {}

        link = ""
        # find the correct binary link with the help of the binaries dict
        if not is_source: 
            # find the correct link for the binary
            for bin_name in binaries_dict:
                # skip the buildinfo file
                if filename.endswith("buildinfo"):
                    continue
                if filename.startswith(bin_name):
                   link = translate_lp_link(binaries_dict[bin_name], release, is_source)
                   break
        #if its a source file, then we're searching in a different way
        else:
            if ".debian.tar" in filename:
                link = translate_lp_link(binaries_dict["diff"], release, is_source)
            elif ".dsc" in filename:
                link = translate_lp_link(binaries_dict["dsc"], release, is_source)
            elif "orig.tar" in filename:
                link = translate_lp_link(binaries_dict["orig"], release, is_source)
            # the above three are the only source links that we want in the USN
            else:
                continue

        if link != "":
            # Store in the dict with the correct format
            files_dict[link] = {
                "md5": md5,
                "size": size
            }

    return files_dict

def split_package(pkg):
    """
    Helper to split the package in its metadata
    """
    tmp = pkg.split('_')
    arch = tmp[-1].split('.')[0]
    pkg_name = tmp[-3].split('/')[-1]
    return (pkg_name, arch)

def load_pkg_details_from_lp(archive, pkgs, binaries, pkg, item, debug=False):
    """
    Function to construct the binaries and packages lists.
    Vendored from sis-generate-usn
    """
    rel = item.distro_series.name
    if debug:
        print("Processing %s" % (rel), file=sys.stderr)

    version = item.source_package_version

    if pkg in pkgs and rel in pkgs[pkg]:
        state = version_compare(version, pkgs[pkg][rel]['source']['version'])
        if state < 0:
            print("Skipping %s: %s %s (already have %s)" % (rel, pkg, version, pkgs[pkg][rel]['source']['version']), file=sys.stderr)
            return
        elif state == 0:
            print("Skipping %s: %s %s (same as %s)" % (rel, pkg, version, pkgs[pkg][rel]['source']['version']), file=sys.stderr)
            return
        else:
            print("Forgetting %s: %s %s (now have %s)" % (rel, pkg, pkgs[pkg][rel]['source']['version'], version), file=sys.stderr)
            pkgs[pkg][rel] = dict()
            binaries[pkg][rel] = dict()
    pkgs.setdefault(pkg, dict())
    pkgs[pkg].setdefault(rel, dict())
    if debug:
        print("Source(%s): %s %s" % (rel, pkg, version), file=sys.stderr)

    # Source details
    pkgs[pkg][rel].setdefault('source', dict())
    pkgs[pkg][rel]['source'].setdefault('version', version)

    # Handle transition to method (LP: #474876)
    if hasattr(item, 'changes_file_url'):
        src_changes = item.changes_file_url
    else:
        src_changes = item.changesFileUrl()

    pkgs[pkg][rel]['source'].setdefault('changes', src_changes)
    if debug:
        print("Source(%s) changes: %s" % (rel, src_changes), file=sys.stderr)

    # Get per-build items
    builds = item.getBuilds()
    # If we didn't find a build, we're in trouble.
    # This can happen if something was pocket-copied from a different release
    # First, see if we can find the builds published in another release.
    # See LP: #783613
    if len(builds) == 0:
        print("Warning: no builds found for source(%s): %s %s" % (rel, pkg, version), file=sys.stderr)
        params = dict(
            source_name=pkg,
            exact_match=True,
            status="Published",
            version = item.source_package_version,
        )
        others = archive.getPublishedSources(**params)
        other = None
        for other in others:
            other_builds = other.getBuilds()
            if len(other_builds) > 0:
                builds = other_builds
                print("Warning: using builds from (%s/%s) for source(%s): %s %s" % (other.distro_series.name, other.pocket, rel, pkg, version), file=sys.stderr)
                print("=== Double check this is what you want ===", file=sys.stderr)
                break

    if len(builds) == 0:
        # raise ValueError("Could not find any builds for %s." % (pkg))
        print("Could not find any builds for %s." % (pkg))
        return

    for build in builds:
        arch = build.arch_tag
        state = build.buildstate
        if debug:
            print("Build(%s,%s) %s" % (rel, arch, state), file=sys.stderr)
        if state == 'Failed to build':
            # don't add records if the build failed
            continue
        elif state == 'Successful build':
            # Work around LP: #559591
            state = 'Successfully built'
        pkgs[pkg][rel].setdefault(arch, dict())
        pkgs[pkg][rel][arch].setdefault('build_state', state)
        bin_changes = build.changesfile_url
        pkgs[pkg][rel][arch].setdefault('changes', bin_changes)
        if debug:
            print("Build(%s,%s) changes: %s" % (rel, arch, bin_changes), file=sys.stderr)
        build_log = build.build_log_url
        pkgs[pkg][rel][arch].setdefault('build_log', build_log)

    # Diff (we don't use this yet...)
    # diff_url = item.packageDiffUrl()
    # pkgs[pkg][rel]['source'].setdefault('ancestor-diff', diff_url)
    # if debug:
    #     print("Diff(%s) URL: %s" % (rel, diff_url), file=sys.stderr)

    # Binary outputs
    # Handle transition to method (LP: #474876)
    if hasattr(item, 'binary_file_url'):
        bin_files = item.binary_file_urls
    else:
        bin_files = item.binaryFileUrls()
    for file_url in bin_files:
        if file_url.endswith('deb'):
            name, arch = split_package(file_url)
            # skip debug binaries
            if filter_dbg.search(name):
                continue
            if debug:
                print("Binary(%s,%s) URL: %s" % (rel, arch, file_url), file=sys.stderr)
                # print(scan_dsc_for_orig(file_url))
            # hack for "all": attach to all_arch
            if arch == 'all':
                all_arch = cve_lib.get_all_arch(rel)
                # if only building for one arch that's not the default
                # all arch, the all packages will be built under that arch
                # so check the all_arch has binary pkgs
                archs = [x for x in list(pkgs[pkg][rel].keys()) if x != 'source']
                if all_arch in archs:
                    arch = all_arch
                elif len(archs) == 1:
                    arch = archs[0]
                elif debug:
                    print("Couldn't find 'all' arch for %s in %s/%s" % (name, arch, rel), file=sys.stderr)
            if not cve_lib.arch_is_valid_for_release(arch, rel):
                if debug:
                    print("Skipping %s binary because %s is not a valid arch in %s" % (name, arch, rel), file=sys.stderr)
                continue
            if not arch in pkgs[pkg][rel]:
                # this architecture is not present from the build
                # records, this can happen when pocket copied from a
                # different pocket or release.
                pkgs[pkg][rel].setdefault(arch, dict())
            pkgs[pkg][rel][arch].setdefault('binaries', dict())
            pkgs[pkg][rel][arch]['binaries'].setdefault(name, file_url)
        else:
            raise ValueError("Unknown downloadable binary file from %s %s '%s'" % (pkg, version, file_url))

    # Source inputs
    # Handle transition to method (LP: #474876)
    if hasattr(item, 'source_file_url'):
        src_files = item.source_file_urls
    else:
        src_files = item.sourceFileUrls()
    for file_url in src_files:
        if file_url.endswith('.dsc'):
            pkgs[pkg][rel]['source'].setdefault('dsc', file_url)
            if debug:
                print("Source(%s) dsc URL: %s" % (rel, file_url), file=sys.stderr)
        elif re.search(r'\.(diff\.gz|debian\.tar\.(gz|bz2|lzma|xz))$', file_url):
            pkgs[pkg][rel]['source'].setdefault('diff', file_url)
            if debug:
                print("Source(%s) debian differences URL: %s" % (rel, file_url), file=sys.stderr)
        elif re.search(r'\.tar\.(gz|bz2|lzma|xz)$', file_url):
            pkgs[pkg][rel]['source'].setdefault('orig', file_url)
            if debug:
                print("Source(%s) orig URL: %s" % (rel, file_url), file=sys.stderr)
        elif file_url.endswith('.asc'):
            pkgs[pkg][rel]['source'].setdefault('asc', file_url)
            if debug:
                print("Source(%s) asc URL: %s" % (rel, file_url), file=sys.stderr)
        else:
            raise ValueError("Unknown downloadable source file from %s %s '%s'" % (pkg, version, file_url))

    binaries.setdefault(pkg, dict())
    binaries[pkg].setdefault(rel, dict())

    # map binaries as pkg -> rel -> binary -> dict(version, origin, pocket)
    # where:
    #    version = actual version
    #    pocket = main, esm-infra-legacy, esm-infra, esm-apps-legacy, esm-apps (based on guesswork)
    #    origin = originating archive/ppa name
    # this is used by sis-generate-usn to know what the actual
    # binary package version is since this may be different than
    # the version of the source package. Also check that all built
    # binaries have actually published into the PPA
    # it is also used to determine what the ACTUAL binary packages

    for binary in item.getPublishedBinaries():
        # collect binary versions

        # skip debian-installer packages, these are udebs we don't want.
        if binary.section_name == 'debian-installer':
            if debug:
                print(
                    "skipping debian-instaler binary file %s from source %s"
                    % (binary.binary_package_name, item.display_name),
                    file=sys.stderr
                )
            continue
        # skip debug binaries
        if filter_dbg.search(binary.binary_package_name):
            continue

        url = ""
        # because a binary can be published for only one arch (and not
        # even the all_arch arch), we need to iterate over all the
        # arches until we find a valid one.
        for arch in cve_lib.official_architectures:
            if not cve_lib.arch_is_valid_for_release(arch, rel) or arch not in pkgs[pkg][rel]:
                continue
            if 'binaries' in pkgs[pkg][rel][arch] and binary.binary_package_name in pkgs[pkg][rel][arch]['binaries']:
                url = pkgs[pkg][rel][arch]['binaries'][binary.binary_package_name]
                break
        pocket = "security"
        for esm_pocket in ["esm-infra-legacy", "esm-infra", "esm-apps-legacy", "esm-apps"]:
            if esm_pocket in url:
                pocket = esm_pocket
                break
        binaries[pkg][rel].setdefault(binary.binary_package_name, {
            'pocket': pocket,
            'source': pkg,
            'version': binary.binary_package_version,
        })
        if binary.status != 'Published':
            if debug:
                print("BinaryPublication(%s,%s,%s) state: %s" % (rel, binary.distro_arch_series.architecture_tag, binary.binary_package_name, binary.status), file=sys.stderr)
            arch = binary.distro_arch_series.architecture_tag
            # Override binary target in the case of "all"
            if 'all' in pkgs[pkg][rel]:
                arch = 'all'
            pkgs[pkg][rel][arch]['build_state'] = 'Binaries pending'

def get_binaries_dict(source_packages_names, releases, ppas, minimum_info):
    """
    Get the dictionary of binaries given the releases, packages and esm ppas that appear in the USN.
    minimum_info = true: get a simple binaries dict for generating the template
    minimum_info = false: get the full binaries dict
    """
    # Dictionaries to store the results
    pkgs = {}
    binaries = {}
    if releases == None:
        releases = supported_releases
    if ppas == None:
        ppas = supported_ppas
    for source_package_name in source_packages_names:
        for ppa_name in ppas:
            if ppa_name.startswith('esm-'):
                ppa = launchpad.people["ubuntu-esm"].getPPAByName(name=f"{ppa_name}-security-staging")
            elif ppa_name == 'archive':
                ppa = launchpad.people["ubuntu-security-proposed"].getPPAByName(name="ppa")
            elif ppa_name == 'private':
                ppa = launchpad.people["ubuntu-security"].getPPAByName(name="ppa")
            elif ppa_name.startswith('private-esm-'):
                ppa = launchpad.people["ubuntu-esm"].getPPAByName(name=f"{ppa_name}-security")
            # TODO: enhance with more PPAs
            else:
                print(ppa_name)
                print_error("Arguments in --ppa should either be esm-*, private-esm-*, private, or archive")
                exit(1)
            # get the source packages matching this pakcage and this release
            published_sources = ppa.getPublishedSources(status="Published", source_name=source_package_name)
            # grab all the sources found in the proposed PPA
            for source in published_sources:
                # minimum info for binaries is required when we are generating the template
                if minimum_info:
                    binary_packages = source.getPublishedBinaries()
                    # check that there is at least one binary
                    if len(binary_packages) == 0:
                        print_error("No binary artifacts found. Make sure that the builds are finished in the proposed PPA and run again")
                        exit(1)
                    release = source.distro_series.name
                    if not release in releases:
                        continue
                    for binary in binary_packages:
                        if (release in binaries) and (binary.binary_package_name in binaries[release]):
                            continue
                        else:
                            # skip debug binaries
                            if not filter_dbg.search(binary.binary_package_name):
                                binary_info = {
                                    "binary_package_name": binary.binary_package_name,
                                }
                                # Add to the dictionary
                                if release not in binaries:
                                    binaries[release] = []
                                binaries[release].append(binary_info)
                else:
                    # Get associated binary packages
                    load_pkg_details_from_lp(ppa, pkgs, binaries, source_package_name, source)
    return pkgs, binaries

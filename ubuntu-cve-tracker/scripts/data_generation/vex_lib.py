# -*- coding: utf-8 -*-
# Module containing classes that are used to generate OpenVEX data for CVEs and USNs
#
# Author: Nick Galanis <nick.galanis@canonical.com>
# Copyright (C) 2024 Canonical Ltd.
#
# This script is distributed under the terms and conditions of the GNU General
# Public License, "Version" 3 or later. See http://www.gnu.org/copyleft/gpl.html
# for details.
#

from datetime import datetime
from data_generation.utils import generate_purl, get_vex_doc_version, prepare_output_dir

import json
import logging
import os

logger = logging.getLogger(__name__)

class VexDocument:
    id: str
    timestamp: datetime
    version: int
    endpoint: str

    def __init__(self, version, releases=None):
        self.cve_storage = None
        self.package_storage = None
        self.version = version
        self.releases = releases
        self.id = self.init_id()

    def generate_metadata(self):
        metadata = {
            "@context": "https://openvex.dev/ns/v0.2.0",
            "@id": self.id,
            "author": "Canonical Ltd.",
            "timestamp": datetime.now().isoformat(),
            "version": self.version
        }

        return metadata

    def generate_binary_product(self, pkg, arch):
        _id = generate_purl(pkg.name, pkg.version.version, arch=arch)
        product = {
            "@id": _id,
        }
        return product

    def generate_source_product(self, src_pkg, fixed_version, release):
        _id = generate_purl(src_pkg.name, fixed_version.version, release=str(release))
        product = {
            "@id": _id,
        }
        return product


class CVE_VEXDocument(VexDocument):
    def __init__(self, cve, version, releases=None):
        self.cve = cve
        cve_year = self.cve.id[4:8]
        self.endpoint = "https://github.com/canonical/ubuntu-security-notices/blob/main/vex/cve/" + cve_year + "/"

        super().__init__(version, releases)

    def init_id(self):
        if not hasattr(self.cve, "id"):
            logger.warning("CVE can not be loaded from cache")
            return None
        return self.endpoint + self.cve.id

    def create_status_dict(self):
        """
        Function to organize cve-pkg entries per their status, in order
        to be easy to parse from the VEX generator
        """
        subproject_status_dict = {}
        for release in self.cve.get_releases():
            if self.releases and release not in self.releases['vex']:
                continue

            subproject = None
            # if release has a progenitor then group together
            if release.get_oldest_parent():
                subproject = release.get_oldest_parent().product
            else:
                subproject = release.product
            if subproject not in subproject_status_dict:
                subproject_status_dict[subproject] = {}
            for entry in self.cve.get_entries_affecting_release(release):
                if entry.status not in subproject_status_dict[subproject]:
                    subproject_status_dict[subproject][entry.status] = []
                subproject_status_dict[subproject][entry.status].append(entry)

        return subproject_status_dict

    def generate_vulnerability(self):
        if not self.cve.id:
            logger.critical("CVE does not have an id. Exiting")
            exit(1)

        if not hasattr(self.cve, "description"):
            self.cve.description = ""
        if not hasattr(self.cve, "public_date"):
            self.cve.public_date = ""

        vulnerability = {
            "@id": "https://nvd.nist.gov/vuln/detail/" + self.cve.id,
            "name": self.cve.id,
            "description": self.cve.description.strip().replace('\n', ' '),
            "aliases": self.cve.references + ["https://ubuntu.com/security/" + self.cve.id]
        }

        return vulnerability

    def generate_status(self, entry):
        """
        Function to map each Ubuntu status in an OpenVEX status with its required fields,
        as per the OpenVEX spec v2
        """
        status_dict = {}
        if hasattr(entry, 'release'):
            release = entry.release
        else:
            release = None
        status = entry.status
        if status == 'not-affected':
            status_dict['status'] = 'not_affected'
            status_dict['justification'] = 'vulnerable_code_not_present'
            status_dict['impact_statement'] = 'This package (for the given release), while related to the CVE in some way, is not affected by the issue. CVE notes should contain further information, if needed.'
        elif status == 'DNE':
            status_dict['status'] = 'not_affected'
            status_dict['justification'] = 'component_not_present'
            status_dict['impact_statement'] = 'This package (for the given release) does not exist in the archive.'
        elif status == 'needs-triage':
            status_dict['status'] = 'under_investigation'
            status_dict['status_notes'] = 'The vulnerability of this package (for the given release) is not known and needs to be evaluated.'
        elif status == 'deferred':
            status_dict['status'] = 'under_investigation'
            status_dict['status_notes'] = "This package (for the given release) is vulnerable to the CVE, the problem is understood, but it is currently deferred. Refer to the CVE notes on https://ubuntu.com/security/" + self.cve.id + " for more details."
        elif status == 'needed' or status == 'pending' or status == 'in-progress':
            status_dict['status'] = 'affected'
            status_dict['action_statement'] = "This package (for the given release) is vulnerable to the CVE and needs fixing."
        elif status == 'pending':
            status_dict['status'] = 'affected'
            status_dict['action_statement'] = "This package (for the given release) is vulnerable to the CVE, needs fixing, and it is being actively worked on."
        elif status == 'ignored':
            status_dict['status'] = 'affected'
            if release and not release.is_active:
                # TODO: trusty supported
                status_dict['action_statement'] = "This package (for the given release) is no longer supported. Please upgrade your system."
            else:
                status_dict['action_statement'] = "This package (for the given release) is vulnerable to the CVE, the problem is understood, but the Ubuntu Security Team decided to not fix it. Refer to the CVE notes on https://ubuntu.com/security/" + self.cve.id + " for more details."
        elif status == 'released':
            status_dict['status'] = 'fixed'
            status_dict['status_notes'] = "This package (for the given release) was vulnerable, but an update has been uploaded and published."
            if release:
                if "esm-infra" in release.name:
                    status_dict['status_notes'] += " Available with Ubuntu Pro (infra only)."
                elif "esm-apps" in release.name:
                    status_dict['status_notes'] += " Available with Ubuntu Pro."
        else:
            logger.critical(f"CVE status not supported {self.cve.id}")
            status_dict['status'] = ''
        return status_dict

    def get_issue_date(self):
        return self.cve.public_date

    def generate_statements(self):
        """
        We want one statement per package entry
        Inside the statement, we have many products: the source package itself and the binaries for every arch
        """
        statements = {}
        non_esm_released = []
        non_legacy_released = []
        entries_status_dict = self.create_status_dict()
        # we want to grab the released entries first, so if something is released in a release, it doesn't
        # show up as 'not affected' in another component
        for subproject in entries_status_dict.keys():
            if subproject not in statements:
                statements[subproject] = []
            # we want a custom order of parsing entries: released and ignored are first, then everything else
            custom_order = {'released': 0, 'ignored': 1}  # Define priority for specific keys
            sorted_keys = sorted(
                entries_status_dict[subproject].keys(),
                key=lambda x: custom_order.get(x, 2)
            )
            for status in sorted_keys:
                products = []
                for entry in entries_status_dict[subproject][status]:
                    logger.debug(f"Generating statement for {self.cve.id} {entry.release} {entry.pkg.name} {entry.status}")
                    version = entry.pkg.get_latest_version(entry.release)

                    # if the release has entered legacy, and the package is in main, the only reason to print the status in the
                    # non-legacy release, is that it was already released there. Otherwise, we rely on the package status of the esm release
                    if hasattr(entry.release.parent, "legacy_infra_release") and (entry.release.parent.legacy_infra_release is not None)\
                        and entry.pkg.release_exists(entry.release.parent.legacy_infra_release, False):
                        if status != 'released':
                            continue
                        else:
                            non_legacy_released.append((entry.pkg, entry.release.parent.legacy_infra_release))
                    # Trusty specific: if the package is in trusty, and there is a legacy entry (which implies there was an esm entry as well).
                    # the only reason to print the status in the original trusty release, is that it was already released there.
                    if (entry.release.canon == "ubuntu/trusty" and entry.pkg.release_exists(entry.release.legacy_infra_release, False)):
                        if status != 'released' or status != 'ignored':
                            continue
                        else:
                            non_esm_released.append((entry.pkg, None))
                    # if the release has entered esm, and the package is in main, the only reason to print the status in the
                    # non-esm release, is that it was already released there. Otherwise, we rely on the package status of the esm release
                    if (entry.release.esm_infra_release is not None) and entry.pkg.release_exists(entry.release.esm_infra_release, False):
                        if status != 'released':
                            continue
                        else:
                            non_esm_released.append((entry.pkg, entry.release.esm_infra_release))
                    # if the release has esm-apps, and the package is in unverse, the only reason to prin the status in the non-esm release
                    # is that it was released there (possibly because the cve fix was synced from debian)
                    if (entry.release.esm_apps_release is not None) and entry.pkg.release_exists(entry.release.esm_apps_release, False):
                        if status != 'released':
                            continue
                        else:
                            non_esm_released.append((entry.pkg, entry.release.esm_apps_release))
                    # if we are processing a legacy entry, check if the package was already released in non-legacy (esm + normal release),
                    # so the esm entry does not need to be reported
                    if "legacy" in entry.release.canon:
                        if ((entry.pkg, entry.release) in non_legacy_released) or ((entry.pkg, entry.release) in non_esm_released):
                            continue
                    # if we are processing an esm entry, check if the package was already released in non-esm,
                    # so the esm entry does not need to be reported
                    if entry.release.is_esm:
                        if (entry.pkg, None) in non_esm_released or (entry.pkg, entry.release) in non_esm_released:
                            continue
                    if version is not None:
                        product = self.generate_source_product(entry.pkg, version, entry.release)
                        products.append(product)

                        # for every binary and every one of its archs
                        for binary in entry.pkg.binaries[entry.release][version]:
                            for arch in binary.arches:
                                #output binary package
                                product = self.generate_binary_product(binary, arch)
                                products.append(product)
                    else:
                        logger.info(f"No version found for package {entry.pkg.name}")
                # if we have at least one product in the specific status
                if products != []:
                    # construct the statment and append it in the statements struct
                    statement = {
                        "vulnerability": self.generate_vulnerability(),
                        "timestamp": self.get_issue_date(),
                        "products": products
                    }
                    statement.update(self.generate_status(entry))
                    statements[subproject].append(statement)
                else:
                    logger.debug(f"No products with {self.generate_status(entry)['status']} in package {entry.pkg.name}")
        return statements


class USN_VEXDocument(VexDocument):

    def __init__(self, usn, version):
        self.usn = usn
        self.endpoint = "https://github.com/canonical/ubuntu-security-notices/blob/main/vex/usn/USN-"
        super().__init__(version)

    def init_id(self):
        if not hasattr(self.usn, "id"):
            logger.warning("USN can not be loaded from cache")
            return None
        return self.endpoint + self.usn.id

    def generate_vulnerability(self):
        cves = sorted(self.usn.cves)
        if self.usn.id is None:
            logger.critical("USN does not have an id yet. USN database could be out of sync")
            exit(1)

        vulnerability = {
            "@id": "https://ubuntu.com/security/notices/USN-" + self.usn.id,
            "name": "USN-" + self.usn.id,
            "description": self.usn.description.strip().replace('\n', ' '),
            "aliases": [cve.id for cve in cves]
        }

        return vulnerability

    def generate_status(self, fixed_version):
        status_dict = {}
        status_dict['status'] = 'fixed'
        if self.usn is not None and self.usn.isummary is not None:
            status_dict['status_notes'] = self.usn.isummary.strip().replace('\n', ' ')
        else:
            status_dict['status_notes'] = " "

        if "esm" in fixed_version.version:
            status_dict['status_notes'] += " Available with Ubuntu Pro."
        return status_dict

    def get_issue_date(self):
        dt = datetime.utcfromtimestamp(self.usn.timestamp)
        return dt.strftime('%Y-%m-%d %H:%M:%S.%f')

    def generate_statements(self):
        # Since all the products mentioned in the USN will have the same status (fixed)
        # we are going to generate only one statement, with a fixed status
        products = []
        statements = {
            'ubuntu': []
        }
        statement = {}
        for release in self.usn.get_releases():
            for source_pkg, fixed_version in self.usn.get_package_info_affecting_release(release):
                logger.debug(f"Generating statement for USN-{self.usn.id} {release} {source_pkg.name}")

                version = fixed_version

                #output source package
                product = self.generate_source_product(source_pkg, fixed_version, release)
                products.append(product)

                # for every binary and every one of its archs
                if release in source_pkg.binaries and version in source_pkg.binaries[release]:
                    for binary in source_pkg.binaries[release][version]:
                        for arch in binary.arches:
                            #output binary package
                            product = self.generate_binary_product(binary, arch)
                            products.append(product)
                # There is a case in which package cache does not have the correct binaries.
                # In that case, use them directly from the USN data
                else:
                    logger.info(f"Binaries in package {source_pkg.name} did not match version {version} in package cache. Using raw_binaries from the USN...")
                    for binary in self.usn.get_raw_binaries(release, source_pkg.name):
                        if hasattr(binary, 'arches'):
                            for arch in binary.arches:
                                #output binary package
                                product = self.generate_binary_product(binary, arch)
                                products.append(product)

                statement = {
                    "vulnerability": self.generate_vulnerability(),
                    "timestamp": self.get_issue_date(),
                    "products": products
                }

                statement.update(self.generate_status(fixed_version))

        statements['ubuntu'].append(statement)

        # no statements were generated
        if statement == {}:
            return None

        return statements


def verify_data_modified(file_path, vex_id, statement):
    if os.path.isfile(os.path.join(file_path, f"{vex_id}.json")):
        # if osv file already exists
        with open(os.path.join(file_path, f"{vex_id}.json"), "r") as f:
            current_vex = json.load(f)
            current_statement = current_vex["statements"]
            if current_statement != statement:
                logger.debug(f"{file_path}/{vex_id} modified")
                return True
            else:
                logger.debug(f"unmodified {file_path}/{vex_id}")
                return False
    return True


def generate_vex_document(output_path, data_source, source_object, supported_releases=None):
    version = None
    vex = None
    document = {}

    if data_source == 'cve':
        vex = CVE_VEXDocument(source_object, version, supported_releases)
    elif data_source == 'usn':
        vex = USN_VEXDocument(source_object, version)


    document["metadata"] = vex.generate_metadata()
    statements = vex.generate_statements()

    # we do not want to create empty VEX documents
    if not statements:
        logger.info(f"VEX Document for {source_object.id} has no statements and thus will not be generated.")
        return None

    for subproject in statements.keys():
        filename = ""
        document["statements"] = statements[subproject]

        if output_path:
            if data_source == 'cve':
                path = prepare_output_dir(output_path, subproject, "vex", "cve", source_object.id.split('-')[1])
                if verify_data_modified(path, source_object.id, document["statements"]):
                    version = get_vex_doc_version(os.path.join(path, f"{source_object.id}.json")) + 1
                    document['metadata']['version'] = version
                else:
                    logger.info(f"VEX Document for {source_object.id} not modified and thus will not be generated.")
                    continue
                filename = os.path.join(path, f"{source_object.id}.json")
            elif data_source == 'usn':
                path = prepare_output_dir(output_path, "ubuntu", "vex", "usn")
                if verify_data_modified(path, f"USN-{source_object.id}", document["statements"]):
                    version = get_vex_doc_version(os.path.join(path, f"USN-{source_object.id}.json")) + 1
                    document['metadata']['version'] = version
                else:
                    logger.info(f"VEX Document for {source_object.id} not modified and thus will not be generated.")
                    continue
                filename = os.path.join(path, f"USN-{source_object.id}.json")
            with open(filename, 'w') as fp:
                json.dump(document, fp, indent=2)
    else:
        document['metadata']['version'] = 1

    return document

#!/usr/bin/python3
# -*- coding: utf-8 -*-
# Module containing util functions that are used to generate OpenVEX data for CVEs and USNs
#
# Author: Nick Galanis <nick.galanis@canonical.com>
# Copyright (C) 2024 Canonical Ltd.
#
# This script is distributed under the terms and conditions of the GNU General
# Public License, "Version" 3 or later. See http://www.gnu.org/copyleft/gpl.html
# for details.
#

import git
import json
import logging
import os
import re

from datalib.config import UCT, USN_REPO, SUBPROJECTS
from .config import LAST_SUBPROJ_CVE_DATA_COMMIT, LAST_UCT_CVE_DATA_COMMIT, LAST_USN_DATA_COMMIT


logger = logging.getLogger(__name__)

def get_changed_cves(commit_hash, ubuntu=True):
    """
    Function to grab changed CVEs by running a git diff in UCT
    from a cached commit until the current HEAD
    """
    try:
        if ubuntu:
            repo = git.Repo(UCT)
        else:
            repo = git.Repo(SUBPROJECTS)

        try:
            commit = repo.commit(commit_hash)
        except ValueError:
            commit = list(repo.iter_commits('HEAD', reverse=True))[0]

        diff = commit.diff('HEAD')
        # get only the changed CVE files
        changed_cves = set()

        for cve in diff:
            if "CVE-" in cve.a_path and not cve.a_path.startswith("test/"):
                cve_id = re.search(r'CVE-\d{4}-\d{4,7}', cve.a_path).group(0)
                if not cve_id:
                    print(f"An error has occured while extracting the CVE ID {cve_id}")

                changed_cves.add(cve_id)

        return changed_cves
    except Exception as e:
        logger.error(f"An error occurred: {e}")
        return set()


def get_changed_usns(commit_hash):
    try:
        repo = git.Repo(USN_REPO)
        commit = repo.commit(commit_hash)

        diff = commit.diff('HEAD')
        # get only the changed USN files
        changed_usns = []
        try:
            # usn files in the repo are named: usm/XXXX-Y, and we only want to keep the ID
            changed_usns = [re.search(r'usn/\d{1,6}-\d{1,2}', usn.a_path).group(0)[4:] for usn in diff if usn.a_path.startswith("usn/")]
        except:
            print("An error has occured while extracting the USN ID")

        return changed_usns
    except Exception as e:
        logger.error(f"An error occurred: {e}")
        return []


def read_last_commit_hash(data_type):
    in_file = ""
    commit_hash = ""
    if data_type == 'UCT':
        in_file = LAST_UCT_CVE_DATA_COMMIT
    elif data_type == 'SUBPROJECTS':
        in_file = LAST_SUBPROJ_CVE_DATA_COMMIT
    elif data_type == 'USN':
        in_file = LAST_USN_DATA_COMMIT

    try:
        with open(in_file, 'r') as file:
            commit_hash = file.read().strip()
    except FileNotFoundError:
        logger.critical(f"Commit cache file {in_file} not found")

    return commit_hash


def write_current_commit_hash(data_type):
    try:
        if data_type == 'UCT':
            out_file = LAST_UCT_CVE_DATA_COMMIT
            repo = git.Repo(UCT)
        elif data_type == 'SUBPROJECTS':
            out_file = LAST_SUBPROJ_CVE_DATA_COMMIT
            repo = git.Repo(SUBPROJECTS)
        elif data_type == 'USN':
            out_file = LAST_USN_DATA_COMMIT
            repo = git.Repo(USN_REPO)

        current_commit_hash = repo.head.commit.hexsha
        with open(out_file, 'w+') as file:
            file.write(current_commit_hash)

    except Exception as e:
        logger.critical(f"An error occurred while writing the commit hash file: {e}")


def get_vex_doc_version(vex_file):
    try:
        with open(vex_file, 'r') as file:
            data = json.load(file)
            version = data.get('metadata', {}).get('version')
            return int(version)
    # if the document is not present in the dir, we assume it has not
    # yet been generated for the first time, and thus currently has a version 0
    except FileNotFoundError:
        logger.debug(f"VEX File not found: {vex_file}")
        return 0
    except:
        logger.critical(f"Error in loading vex file:{vex_file}")
        return 0

def prepare_output_dir(output_dir, subproject, data_type, data_source, year=""):
    outdir = os.path.join(os.path.expanduser(output_dir), subproject, data_type, data_source, year)

    if not os.path.exists(outdir):
        logger.warning(f"Creating outputdir dir {outdir}")
        os.makedirs(outdir, 0o775)
    elif not os.path.isdir(outdir):
        logger.error(f"{outdir} is not a directory, existing!")
        exit(1)

    return outdir

def generate_purl(package_name, version, release=None, arch=None):
    purl = ""
    if release is None and arch is not None:
        purl = "pkg:deb/ubuntu/" + package_name + "@" + version + "?arch=" + arch
    elif release is not None:
        purl = "pkg:deb/ubuntu/" + package_name + "@" + version + "?arch=source&distro=" + release
    else:
        raise Exception("Missing parameters needed for purl")
    return purl

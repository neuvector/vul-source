#!/usr/bin/env python3
# Author: Eduardo Barretto <eduardo.barretto@canonical.com>
# Copyright (C) 2023 Canonical, Ltd.
#
# This script is distributed under the terms and conditions of the GNU General
# Public License, Version 3 or later. See http://www.gnu.org/copyleft/gpl.html
# for details.
#

from datetime import datetime
from datalib import Version
from data_generation.utils import generate_purl, prepare_output_dir

import logging
import json
import os
import sys

SCHEMA_VERSION = "1.7.0"
CVE_URL = "https://ubuntu.com/security"
USN_URL = "https://ubuntu.com/security/notices"

CREDITS_TYPE = {
    "FINDER", # identified the vulnerability
    "REPORTER", # notified the vendor of the vulnerability to a CNA
    "ANALYST", # validated the vulnerability to ensure accuracy or severity
    "COORDINATOR", # facilitated the coordinated response process
    "REMEDIATION_DEVELOPER", # prepared a code change or other remediation plans
    "REMEDIATION_REVIEWER", # reviewed vulnerability remediation plans or code changes for effectiveness and completeness
    "REMEDIATION_VERIFIER", # tested and verified the vulnerability or its remediation
    "TOOL", # names of tools used in vulnerability discovery or identification
    "SPONSOR", # supported the vulnerability identification or remediation activities
    "OTHER", # any other type or role that does not fall under the categories described above
}

RANGES_TYPE = {"SEMVER", "ECOSYSTEM", "GIT"}

REFERENCES_TYPE = {
    "ADVISORY",
    "ARTICLE",
    "DETECTION",
    "DISCUSSION",
    "REPORT",
    "FIX",
    "GIT",
    "INTRODUCED",
    "PACKAGE",
    "EVIDENCE",
    "WEB",
}

SEVERITY_TYPE = {"CVSS_V2",  "CVSS_V3", "CVSS_V4", "Ubuntu"}

logger = logging.getLogger(__name__)


class Database:
    """OSV database_specific field"""

    def __init__(self):
        return 0

    def to_dict(self):
        return self.__dict__


class Package:
    """Ubuntu specific info"""
    ecosystem: str
    name: str
    purl: str

    def __init__(self, ecosystem, name, purl):
        self.ecosystem = ecosystem
        self.name = name
        self.purl = purl

    def to_dict(self):
        return self.__dict__


class Event:
    introduced: str
    fixed: str
    last_affected: str
    limit: str

    def __init__(self, introduced, fixed_version=None, last_affected=None, limited=None):
        self.introduced = introduced
        if fixed_version:
            self.fixed = fixed_version
        if last_affected:
            self.last_affected = last_affected
        if limited:
            self.limited = limited

    def to_dict(self):
        result = [{"introduced": self.introduced}]
        if hasattr(self, "fixed"):
            result.append({"fixed": self.fixed})
        if hasattr(self, "last_affected"):
            result.append({"last_affected": self.last_affected})
        if hasattr(self, "limited"):
            result.append({"limited": self.limited})
        return result


class Range:
    type: str
    events: list
    repo: str

    def __init__(self, range_type, events, repo=None):
        if range_type not in RANGES_TYPE:
            logger.critical("Unknown range type")
            sys.exit(1)
        self.type = range_type
        self.events = events
        if repo:
            self.repo = repo

    def to_dict(self):
        return self.__dict__


class Ecosystem:
    binaries: list
    availability: str
    priority_reason: str
    module_name_regex: str

    def __init__(self, binaries, product, priority_reason=None, module_name_regex=None):
        if binaries:
            self.binaries = []
            for binary in binaries:
                bins = {}
                if type(binary) is str:
                    bins['binary_name'] = binary
                    bins['binary_version'] = binaries[binary]['version']
                else:
                    bins['binary_name'] = binary.name
                    bins['binary_version'] = binary.version.version
                self.binaries.append(bins)
            self._update_availability(product)
        if priority_reason:
            self.priority_reason = priority_reason
        if module_name_regex:
            self.availability = "Livepatch subscription required"
            self.module_name_regex = module_name_regex

    def _update_availability(self, product):
        if 'Long Term' in product or 'Interim' in product:
            self.availability = "No subscription required"
        else:
            self.availability = product

    def to_dict(self):
        return self.__dict__


class Severity:
    """OSV severity field"""
    type: str
    score: str

    def __init__(self, sev_type, sev_score):
        if sev_type not in SEVERITY_TYPE:
            logger.critical("Unknown severity type")
            sys.exit(1)
        self.type = sev_type
        self.score = sev_score

    def to_dict(self):
        return self.__dict__


class Affected:
    """OSV affected field"""
    package: Package
    severity: list
    ranges: list
    versions: list
    ecosystem_specific: Ecosystem
    database_specific: Database

    def __init__(self, package, ranges, versions, severity=None, ecosystem=None, database=None):
        self.package = package
        if severity:
            self.severity = severity
        self.ranges = ranges
        self.versions= versions
        if ecosystem:
            self.ecosystem_specific = ecosystem
        if database:
            self.database_specific = database

    def to_dict(self):
        return self.__dict__


class Reference:
    """OSV reference field"""
    type: str
    url: str

    def __init__(self, url_type, url):
        if url_type not in REFERENCES_TYPE:
            logger.critical("Unkown reference type")
            sys.exit(1)
        self.type = url_type
        self.url = url

    def to_dict(self):
        return self.__dict__


class Credits:
    """OSV credits field"""
    name: str
    contact: list
    type: str

    def __init__(self, name, credit_type, contact=None):
        self.name = name
        if credit_type not in CREDITS_TYPE:
            logger.critical("Invalid credits type")
            sys.exit(1)
        self.type = credit_type
        if contact:
            self.contact = contact

    def to_dict(self):
        return self.__dict__


class OSV:
    """OSV structure"""
    schema_version: str
    id: str
    modified: str
    published: str
    withdrawn: str
    aliases: list
    upstream: list
    related: list
    summary: str
    details: str
    severity: list
    affected: list
    references: list
    credits: list
    database: Database

    def __init__(self, id, description, published, modified, withdrawn, affected, references, upstream, related=[], aliases=[], summary=None, severity=None, credit=None, database=None):
        self.schema_version = SCHEMA_VERSION
        self.id = id
        if summary:
            self.summary = summary
        self.details = description
        self.aliases = aliases
        self.upstream = upstream
        self.related = related
        if severity:
            self.severity = severity
        self.published = published
        self.modified = modified
        if withdrawn:
            self.withdrawn = withdrawn
        self.affected = affected
        self.references = references
        if database:
            self.database = database

    def to_dict(self):
        return self.__dict__

    def toJson(self):
        return json.dumps(self, default=lambda o: o.to_dict(), indent=2)


def write_osv(path, osv):
    with open(os.path.join(path, f"{osv.id}.json"), "w") as f:
        f.write(osv.toJson())


def verify_data_modified(path, osv):
    if os.path.isfile(os.path.join(path, f"{osv.id}.json")):
        # if osv file already exists
        filepath = os.path.join(path, f"{osv.id}.json")
        with open(filepath, "r") as f:
            current_osv = json.load(f)
            new_osv = json.loads(osv.toJson())
            del current_osv['modified']
            del new_osv['modified']
            if current_osv != new_osv:
                logger.debug(f"{filepath} modified")
                osv.modified = datetime.utcnow().isoformat(timespec="seconds") + "Z"
                return True
            else:
                logger.debug(f"unmodified {filepath}.json")
                return False
    return True


def data_withdrawn(path, uid):
    if os.path.isfile(os.path.join(path, f"UBUNTU-{uid}.json")):
        # if osv file exists, it means that it was withdrawn/removed
        with open(os.path.join(path, f"UBUNTU-{uid}.json"), "r+") as f:
            current_osv = json.load(f)
            if 'withdrawn' not in current_osv:
                current_osv['withdrawn'] = datetime.utcnow().isoformat(timespec="seconds") + "Z"
                f.seek(0)
                json.dump(current_osv, f, indent=2)
                f.truncate()
    return


def parse_release_entry(cve, release, entry):
    logger.debug(f"{cve.id} {release} {entry.pkg} {entry.status}")
    source_pkg = entry.pkg
    fixed_version = None
    binaries = None

    if entry.note and entry.note[0].isdigit():
        fixed_version = Version(entry.note)
        logger.debug(f"fixed_version: {fixed_version}")

    if entry.status == "DNE":
        logger.debug(f"{release} status is DNE, SKIPPING")
        return None, None, None
    elif entry.status == "ignored":
        if release.is_esm and release.get_oldest_parent().is_active:
            logger.debug(f"{release} status is ignored but parent is active, SKIPPING")
            return None, None, None
        elif not release.is_active:
            logger.debug(f"{release} status is ignored, SKIPPING")
            return None, None, None
    elif entry.status in ["not-affected", "released"]:
        if not fixed_version:
            logger.debug(f"No fixed version for {release}, SKIPPING")
            return None, None, None
        elif fixed_version not in source_pkg.get_release_source_versions(release):
            logger.debug("Fixed version from previous release or parent, SKIPPING")
            return None, None, None
        elif fixed_version in source_pkg.get_release_source_versions(release.parent):
            logger.debug("Fixed version from parent, SKIPPING")
            return None, None, None
        else:
            binaries = source_pkg.binaries[release][fixed_version]
    elif entry.status in ["deferred", "needed", "needs-triage", "pending"]:
        if not release.is_active:
            logger.error(f"{cve} has {release} with status {entry.status}, SKIPPING")
            return None, None, None
        elif release.is_esm and release.get_oldest_parent().is_active:
            logger.debug("Avoid adding {release} because parent is active, SKIPPING")
            return None, None, None
    else:
        logger.critical("Unknown status {entry.status}")
        sys.exit(1)

    return source_pkg, fixed_version, binaries


def get_ecosystem_name(release, is_lsn=False):
    ecosystem = release.name.replace(" ", ":")
    if release.is_esm or (is_lsn and not release.is_fips):
        ecosystem = ecosystem.replace(":", ":Pro:", 1)
    return ecosystem


def get_affected_versions(source, release, fixed_version=None):
    versions = []
    affected_versions = source.get_release_source_versions(release)
    if release.is_esm:
        parent = release.parent
        while parent:
            affected_versions.update(source.get_release_source_versions(parent))
            parent = parent.parent
    for version in sorted(affected_versions):
        if fixed_version and fixed_version <= version:
            continue
        versions.append(version.version)
    return versions


def parse_cvss(cvss):
    cvss_type = cvss.split('/', 1)[0]
    if cvss_type.startswith('AV'):
        cvss_type = 'CVSS_V2'
    elif cvss_type.startswith('CVSS:3'):
        cvss_type = 'CVSS_V3'
    elif cvss_type.startswith('CVSS:4'):
        cvss_type = 'CVSS_V4'
    else:
        logger.critical("Uknown CVSS")
        sys.exit(1)

    return cvss_type


def usn2osv(output_path, usn):
    affected = []
    references = []
    aliases = []
    upstream = []
    related = []
    osv = None

    path = prepare_output_dir(output_path, "ubuntu", "osv", "usn")
    published = datetime.utcfromtimestamp(usn.timestamp).isoformat() + "Z"
    modified = published
    withdrawn = None

    references.append(Reference("ADVISORY", f"{USN_URL}/USN-{usn.id}"))
    for cve in sorted(usn.cves):
        references.append(Reference("REPORT", f"{CVE_URL}/{cve.id}"))
        upstream.append('UBUNTU-' + cve.id)
    for bug in sorted(usn.lp_bugs):
        references.append(Reference("REPORT", bug.split(' ')[0]))

    for release in usn.get_releases():
        logger.debug(f"Processing {usn.id} - {release}")
        binaries = None

        for source_pkg, fixed_version in usn.get_package_info_affecting_release(release):
            if release not in source_pkg.binaries or fixed_version not in source_pkg.binaries[release]:
                logger.debug(f"retrieving raw binaries {usn.id} {release} {source_pkg} {fixed_version}")
                binaries = usn.get_raw_binaries(release, source_pkg.name)
            else:
                binaries = source_pkg.binaries[release][fixed_version]

            ecosystem_name = get_ecosystem_name(release)
            purl = generate_purl(source_pkg.name, fixed_version.version, str(release))
            pkg = Package(ecosystem_name, source_pkg.name, purl)
            event = Event("0", fixed_version.version)
            ranges = [Range("ECOSYSTEM", event)]
            versions = get_affected_versions(source_pkg, release, fixed_version)
            ecosystem = Ecosystem(binaries, release.description)

            affected.append(
                Affected(
                    pkg,
                    ranges,
                    versions,
                    ecosystem=ecosystem
                )
            )

    if affected:
        osv = OSV(
            f'USN-{usn.id}',
            usn.description,
            published,
            modified,
            withdrawn,
            affected,
            references,
            upstream,
            related,
            aliases,
            usn.summary,
        )

    if osv and verify_data_modified(path, osv):
        write_osv(path, osv)

    return 0


def cve2osv(output_path, cve, supported_releases):
    packages = cve.pkg_entries
    if not packages:
        logger.info(f"Skipping {cve} as there are no known supported releases")
        return

    references = []
    aliases = []
    upstream = []
    related = []
    severity = []
    osv = None
    subproject_affected = {}

    published = cve.get_public_date() + "Z"
    modified = published
    withdrawn = None
    upstream.append(cve.id)

    for entry in cve.cvss:
        sev_type = parse_cvss(entry.vector)
        severity.append(Severity(sev_type, entry.vector))
    if cve.priority != "untriaged":
        severity.append(Severity("Ubuntu", cve.priority))

    references.append(Reference("REPORT", f"{CVE_URL}/{cve.id}"))
    for ref in cve.references:
        if "USN-" in ref:
            related.append(ref.split('/')[-1])
            references.append(Reference("ADVISORY", ref.split(' ')[0]))
        else:
            references.append(Reference("REPORT", ref.split(' ')[0]))

    for release in cve.get_releases():
        logger.debug(f"Processing {cve.id} - {release}")
        if release not in supported_releases['osv']:
            continue
        subproject = None
        # if release has a progenitor then group together
        if release.get_oldest_parent():
            subproject = release.get_oldest_parent().product
        else:
            subproject = release.product
        if subproject not in subproject_affected:
            subproject_affected[subproject] = []

        for entry in cve.get_entries_affecting_release(release):
            source_pkg, fixed_version, binaries = parse_release_entry(cve, release, entry)
            if source_pkg is None:
                continue

            ecosystem_name = get_ecosystem_name(release)
            if fixed_version is not None:
                purl = generate_purl(source_pkg.name, fixed_version.version, str(release))
                event = Event("0", fixed_version.version)
            else:
                version = None
                rel = release
                while version is None:
                    version = source_pkg.get_latest_version(rel)
                    rel = rel.parent

                purl = generate_purl(source_pkg.name, version.version, str(release))
                event = Event("0", None)

            pkg = Package(ecosystem_name, source_pkg.name, purl)
            ranges = [Range("ECOSYSTEM", event)]
            versions = get_affected_versions(source_pkg, release, fixed_version)
            ecosystem = Ecosystem(binaries, release.description, cve.priority_reason)

            subproject_affected[subproject].append(
                Affected(
                    pkg,
                    ranges,
                    versions,
                    ecosystem=ecosystem
                )
            )

    for subproject in subproject_affected:
        path = prepare_output_dir(output_path, subproject, "osv", "cve", cve.id.split('-')[1])
        if not subproject_affected[subproject]:
            data_withdrawn(path, cve.id)
            continue
        if cve.in_ignored:
            data_withdrawn(path, cve.id)
            continue
        osv = OSV(
            f'UBUNTU-{cve.id}',
            cve.description,
            published,
            modified,
            withdrawn,
            subproject_affected[subproject],
            references,
            upstream,
            related,
            aliases,
            severity=severity,
        )
        path = prepare_output_dir(output_path, subproject, "osv", "cve", cve.id.split('-')[1])
        if verify_data_modified(path, osv):
            write_osv(path, osv)

    return 0


def lsn2osv(output_path, lsn):
    affected = []
    references = []
    aliases = []
    upstream = []
    related = []
    osv = None

    path = prepare_output_dir(output_path, "ubuntu", "osv", "lsn")
    published = datetime.utcfromtimestamp(lsn.timestamp).isoformat() + "Z"
    modified = published
    withdrawn = None

    references.append(Reference("ADVISORY", f"{USN_URL}/{lsn.id}"))
    for cve in sorted(lsn.cves):
        references.append(Reference("REPORT", f"{CVE_URL}/{cve.id}"))
        upstream.append('UBUNTU-' + cve.id)

    for release in lsn.releases:
        logger.debug(f'Processing {lsn.id} - {release}')
        for fixed_release, source_pkg, fixed_version, module_name_regex in lsn.get_fixed_info_affecting_release(release):
            version = None
            if fixed_version is None:
                rel = fixed_release
                while version is None:
                    version = source_pkg.get_latest_version(rel)
                    rel = rel.parent
            else:
                version = fixed_version

            ecosystem_name = get_ecosystem_name(fixed_release, True)
            if fixed_version is not None:
                purl = generate_purl(source_pkg.name, fixed_version.version, str(fixed_release))
                event = Event("0", fixed_version.version)
            else:
                version = None
                rel = release
                while version is None:
                    version = source_pkg.get_latest_version(rel)
                    rel = rel.parent

                purl = generate_purl(source_pkg.name, version.version, str(fixed_release))
                event = Event("0", None)

            pkg = Package(ecosystem_name, source_pkg.name, purl)
            ranges = [Range("ECOSYSTEM", event)]
            versions = get_affected_versions(source_pkg, fixed_release, fixed_version)
            ecosystem = Ecosystem(None, fixed_release.description, module_name_regex=module_name_regex)

            affected.append(
                Affected(
                    pkg,
                    ranges,
                    versions,
                    ecosystem=ecosystem,
                )
            )

    if affected:
        osv = OSV(
            lsn.id,
            lsn.description,
            published,
            modified,
            withdrawn,
            affected,
            references,
            upstream,
            related,
            aliases,
            lsn.title
        )
    if osv and verify_data_modified(path, osv):
        write_osv(path, osv)

    return 0
